# -*- coding: utf-8 -*-
"""TinyImageNetLoader.ipynb
Automatically generated by Colaboratory.
reference from: https://github.com/pranavphoenix/TinyImageNetLoader/blob/main/tinyimagenetloader.py
"""

#loads images as 3*64*64 tensors 

# !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip
# !unzip -q tiny-imagenet-200.zip

import torch
import torchvision
import cv2
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.utils.data import Dataset
import os, glob
from torchvision.io import read_image, ImageReadMode

id_dict = {}
toPIL = transforms.ToPILImage()
toTensor = transforms.ToTensor()

for i, line in enumerate(open('data/tiny-imagenet-200/wnids.txt', 'r')):
  id_dict[line.replace('\n', '')] = i

class TrainTinyImageNetDataset(Dataset):
    def __init__(self, id, transform=None):
        self.filenames = glob.glob("data/tiny-imagenet-200/train/*/*/*.JPEG")
        self.transform = transform
        self.id_dict = id

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        img_path = self.filenames[idx]
        image = read_image(img_path)
        if image.shape[0] == 1: 
            # image = image.numpy().transpose((1, 2, 0))
            # image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            # image = toTensor(image) * 255
            image = read_image(img_path,ImageReadMode.RGB)
        label = self.id_dict[img_path.split('/')[3]]
        image = image.type(torch.FloatTensor) / 255
        if self.transform:
            image = self.transform(image)
        return image, label

class TestTinyImageNetDataset(Dataset):
    def __init__(self, id, transform=None):
        self.filenames = glob.glob("data/tiny-imagenet-200/val/images/*.JPEG")
        self.transform = transform
        self.id_dict = id
        self.cls_dic = {}
        for i, line in enumerate(open('data/tiny-imagenet-200/val/val_annotations.txt', 'r')):
            a = line.split('\t')
            img, cls_id = a[0],a[1]
            self.cls_dic[img] = self.id_dict[cls_id]
 

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        img_path = self.filenames[idx]
        image = read_image(img_path)
        if image.shape[0] == 1: 
            # image = image.numpy().transpose((1, 2, 0))
            # image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            # image = toTensor(image) * 255
            image = read_image(img_path,ImageReadMode.RGB)
        image = image.type(torch.FloatTensor) / 255
        label = self.cls_dic[img_path.split('/')[-1]]
        if self.transform:
            image = self.transform(image)
        return image, label

# 一个奇怪的现象：
# 1. 似乎 train_transform 包含 CenterCrop 之后会导致训练失败（输出全 nan），但是 RandomCrop 不会导致这个问题。
# 但是使用 RandomCrop(32, padding=4) 无疑也限制了模型的性能（数据不全）.
# 2. RandomCrop(32, padding=4) 设置为 RandomCrop(32, padding=4) nan 训练时 (输出全 nan)
# 3. Dataloader numworks 设置由 4 变为 0，又神奇地可以训练了。
# 4. Dataloader numworkers 由 0 变为 2，依然可以正常训练 (naturally training & AT(TRADES))
# 5. 在 num_workers 设置为 2 的条件下，修改 resnet 以及 WRN 结构超参数，发现可以正常训。
# 6. 某些 run 下依然会失败，loss 变为 nan ，训练不稳定。 （2/3 失败率）
# 7. tiny-imagenet 的归一化或许导致部分样本在 attackGPD 下极为不稳定，猜想是样本扰动率过大，从而训练失败。
# 取消 normalize 之后有待观察。(1/3 失败率)
# 8. 原因待查，基本规律是只在 trades + resnet 发现此问题（nan output），其他组暂无此问题。
# 9. 同样的配置，cifar10 + trades + resnet 将 TRADES loss 加入温度常数，失败组重新正常。

def tiny_imagenet_loader(train_shuffle=True, test_shuffle=False, train_batch_size=64, test_batch_size=64):
    # normalize = transforms.Normalize((122.4786, 114.2755, 101.3963), (70.4924, 68.5679, 71.8127))
    train_transform = transforms.Compose([
        # normalize,
        transforms.RandomHorizontalFlip(),
        # transforms.RandomCrop(32, padding=None),
        # transforms.RandomCrop(32, padding=4),
        # transforms.CenterCrop(32),
    ])

    test_transform = transforms.Compose([
        # normalize,
        # transforms.CenterCrop(32),
    ])

    trainset = TrainTinyImageNetDataset(id=id_dict, transform=train_transform)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=train_shuffle, num_workers=0)

    testset = TestTinyImageNetDataset(id=id_dict, transform=test_transform)
    testloader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=test_shuffle, num_workers=0)

    return trainloader, testloader
